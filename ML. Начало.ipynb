{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Асимптотический анализ\n",
    "\n",
    "Эффективность алгоритма зависит от следующих параметров: время выполнения, объем памяти и других ресурсов, необходимых для его выполнения. Эффективность измеряется с помощью асимптотических нотаций.\n",
    "\n",
    "Производительность алгоритма может отличаться при работе с различными типами данных. С увеличением количества входных данных она также изменяется.\n",
    "\n",
    "**Асимптотический анализ** – метод изучения производительности алгоритмов при различных объемах и типах входных данных.\n",
    "\n",
    "В основном используются три нотации:\n",
    "\n",
    "- Большое «О» (Big-O Notation (O-notation))\n",
    "- Омега нотация (Omega Notation (Ω-notation))\n",
    "- Тета нотация (Theta Notation (Θ-notation))\n",
    "\n",
    "`O-нотация` или `Большое «О»` – используется для описания производительности алгоритмов в зависимости от размера входных данных. Она показывает, как изменяется время выполнения или использование памяти, по мере роста объёма данных. Так как эта нотация дает нам представления о верхней границе, т.е. худшей скорости выполнения алгоритма, то ее анализ обязателен – нам всегда интересна эта характеристика.\n",
    "\n",
    "`Омега нотация` – противоположность большому «О». Она показывает нижнюю границу скорости выполнения алгоритма. Она описывает лучший случай выполнения алгоритма.\n",
    "\n",
    "`Тета нотация` объединяет в себе сразу две функции – верхнюю и нижнюю. Эта нотация отражает и верхнюю, и нижнюю границу скорости выполнения алгоритма. Именно поэтому она используется для анализа средней скорости выполнения алгоритма.\n",
    "\n",
    "Нас интересует, в большей степени, именно O-нотация, поэтому разбираться будем с ней.\n",
    "\n",
    "`Линейный поиск` обозначается как O(n) – время выполнения зависит от количества элементов в списке. Если список увеличивается в два раза, время выполнения также увеличится в два раза.\n",
    "\n",
    "`Бинарный поиск` обозначается как O(log n) – время выполнения зависит от логарифма количества элементов. Если список увеличивается в два раза, время выполнения увеличится незначительно.\n",
    "\n",
    "### Виды О-нотаций\n",
    "\n",
    "![Ошибка загрузки](https://github.com/akazachkov/ML_lesson_material/blob/main/_add_material_lesson_ML/O-notation.png?raw=true)\n",
    "\n",
    "# Сравнение структур данных\n",
    "\n",
    "![Ошибка загрузки](https://github.com/akazachkov/ML_lesson_material/blob/main/_add_material_lesson_ML/Compare_data_structures.png?raw=true)\n",
    "\n",
    "Списки (Lists) – подходят для хранения упорядоченных коллекций элементов с быстрым доступом по индексу, но операции поиска и удаления могут быть медленными.\n",
    "\n",
    "Кортежи (Tuples) – имеют те же преимущества и недостатки, что и списки, но неизменяемы.\n",
    "\n",
    "Множества (Sets) – отлично подходят для хранения уникальных элементов и выполнения быстрых операций поиска, добавления и удаления.\n",
    "\n",
    "Словари (Dictionaries) – идеальны для хранения пар ключ-значение с быстрым доступом, поиском, добавлением и удалением элементов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическая часть\n",
    "\n",
    "Посмотрим на примере, разницу в скорости поиска информации в списке и словаре. Для этого сгенерируем данные и запустим поиск, с расчётом затраченного времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Создание тестовых данных\n",
    "\n",
    "def generate_contacts_list(n):\n",
    "    contacts = []\n",
    "    for _ in range(n):\n",
    "        name = ''.join(random.choices(string.ascii_letters, k=10))\n",
    "        phone = ''.join(random.choices(string.digits, k=10))\n",
    "        email = f'{name.lower()}@example.com'\n",
    "        contacts.append([name, phone, email])\n",
    "    return contacts\n",
    "\n",
    "def generate_contacts_dict(n):\n",
    "    contacts = {}\n",
    "    for _ in range(n):\n",
    "        name = ''.join(random.choices(string.ascii_letters, k=10))\n",
    "        phone = ''.join(random.choices(string.digits, k=10))\n",
    "        email = f'{name.lower()}@example.com'\n",
    "        contacts[name] = {'phone': phone, 'email': email}\n",
    "    return contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация данных (если сгенерировать меньшее число данных, разницу можно не увидеть. Больше - займёт время и может \"подвесить\" компьютер)\n",
    "\n",
    "n = 1000000\n",
    "contacts_list = generate_contacts_list(n)\n",
    "contacts_dict = generate_contacts_dict(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбор случайного имени, которое мы будем искать с помощью дальнейших функций\n",
    "\n",
    "random_name = contacts_list[random.randint(0, n-1)][0]\n",
    "random_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Время поиска в списке\n",
    "\n",
    "def find_contact_list(contacts, name):\n",
    "  for contact in contacts:\n",
    "    if contact[0] == name:\n",
    "      return contact\n",
    "  return None\n",
    "\n",
    "start_time = time.time()\n",
    "find_contact_list(contacts_list, random_name)\n",
    "list_search_time = time.time() - start_time\n",
    "list_search_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Время поиска в словаре\n",
    "\n",
    "def find_contact_dict(contacts, name):\n",
    "    return contacts.get(name, None)\n",
    "\n",
    "start_time = time.time()\n",
    "find_contact_dict(contacts_dict, random_name)\n",
    "dict_search_time = time.time() - start_time\n",
    "dict_search_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На моём компьютере, поиск по листу занимает 20-50 ms. По словарю поиск происходит настолько быстро, что в большинстве случаев выводится 0 ns. Лишь раз, за десятки итераций, на поиск по словарю ушло 998 µs. Разница значительна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1. Управление библиотекой книг\n",
    "\n",
    "Создаём систему управления библиотекой, которая позволяет добавлять книги, удалять книги, искать книги по названию и автору."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = {}  # Создаём пустой словарь и определяем функции\n",
    "\n",
    "def add_book(title, author, year):\n",
    "    '''Функция для добавления книги'''\n",
    "    library[title] = {'author': author, 'year': year}\n",
    "\n",
    "def remove_book(title):\n",
    "    '''Функция для удаления книги'''\n",
    "    if title in library:\n",
    "        del library[title]\n",
    "\n",
    "def find_book_by_title(title):\n",
    "    '''Функция для поиска книги по названию'''\n",
    "    return library.get(title, None)\n",
    "\n",
    "def find_books_by_author(author):\n",
    "    '''Функция для поиска книги по автору'''\n",
    "    return {title: info for title, info in library.items()\n",
    "        if info['author'] == author}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем книгу и смотрим результат\n",
    "\n",
    "add_book('Python 101', 'Andrew', 2029)\n",
    "library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем ещё книгу и смотрим результат\n",
    "\n",
    "add_book('Python ML', 'Steve', 2024)\n",
    "library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем поиск по словарю\n",
    "\n",
    "print(find_book_by_title('Python 101'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(find_books_by_author('Andrew'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим ещё одну книгу уже известного автора и посмотрим что выдаст поиск\n",
    "\n",
    "add_book('Python 102', 'Andrew', 2029)\n",
    "find_books_by_author('Andrew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим одну из книг из словаря\n",
    "\n",
    "remove_book('Python 102')\n",
    "library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2. Аналитическая задача\n",
    "\n",
    "Напишем программу для анализа данных о продажах, загружая их из Excel-файла. Программа должна уметь загружать данные, выполнять базовый анализ и выводить результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl  # Для установки в windows, ввести в терминале    py -m pip install openpyxl\n",
    "\n",
    "def load_data(filename):\n",
    "    workbook = openpyxl.load_workbook(filename)\n",
    "    sheet = workbook.active\n",
    "    data = []\n",
    "\n",
    "    for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row, values_only=True):\n",
    "        data.append({'date': row[0], 'sales': row[1], 'category': row[2]})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('_add_material_lesson_ML\\\\sales.xlsx')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales = sum(item['sales'] for item in data)\n",
    "total_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sales_day = max(data, key=lambda x: x['sales'])\n",
    "print(f\"День с максимальными продажами: {max_sales_day['date']} - {max_sales_day['sales']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подсчёт количества продаж по категориям\n",
    "\n",
    "category_sales = {}\n",
    "for item in data:\n",
    "    category = item['category']\n",
    "    sales = item['sales']\n",
    "    if category in category_sales:\n",
    "        category_sales[category] += sales\n",
    "    else:\n",
    "        category_sales[category] = sales\n",
    "\n",
    "print('Продажи по категориям:')\n",
    "for category, sales in category_sales.items():\n",
    "    print(f'{category}: {sales}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3. Базовая статистика\n",
    "\n",
    "Напишем программу для вывода среднего значения, моды и медианы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 1000, 3, 3, 13, 3, 6, 6, 7, 9, 9, 8, 9, 10, 10, 11, 12, 3, 14, 14, 14, 15, 15, 500]\n",
    "print(type(data))\n",
    "\n",
    "def calculate_mean(data):\n",
    "    '''Расчёт среднего значения'''\n",
    "    total = sum(data)\n",
    "    count = len(data)\n",
    "    mean = total/count\n",
    "    return mean\n",
    "\n",
    "def calculate_mode(data):\n",
    "    '''Расчёт моды'''\n",
    "    frequency={}\n",
    "    for value in data:\n",
    "        if value in frequency:\n",
    "            frequency[value] += 1\n",
    "        else:\n",
    "            frequency[value] = 1\n",
    "    max_freq = max(frequency.values())\n",
    "    modes = [key for key, val in frequency.items() if val == max_freq]\n",
    "    return modes\n",
    "\n",
    "def calculate_median(data):\n",
    "\n",
    "    data.sort()  # Для начала, сортируем данные по убыванию\n",
    "\n",
    "    '''Расчёт медианы'''\n",
    "    n = len(data)\n",
    "    if n % 2 == 0:\n",
    "        median = (data[n//2 - 1] + data[n//2]) / 2\n",
    "    else:\n",
    "        median = data[n//2]\n",
    "\n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_mean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_mode(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_median(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4. Анализ текста\n",
    "\n",
    "Напишем программу, которая анализирует текст, введенный пользователем, и выводит общее количество слов, количество уникальных слов и самое частое слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(text):\n",
    "\n",
    "    # Разбиваем текст на слова\n",
    "    words = text.split()\n",
    "\n",
    "    # Считаем количество слов\n",
    "    total_words = len(words)\n",
    "\n",
    "    # Считаем количество уникальных слов\n",
    "    unqiue_words = len(set(words))\n",
    "\n",
    "    # Подсчёт частоты каждого слова\n",
    "    word_frequency = {}\n",
    "    for word in words:\n",
    "        word = word.lower().strip(\".,!?;:\")  # Приведение к нижнему регистру и удаление знаков препинания\n",
    "        if word in word_frequency:\n",
    "            word_frequency[word] += 1\n",
    "        else:\n",
    "            word_frequency[word] = 1\n",
    "\n",
    "    most_frequent_word = max(word_frequency, key=word_frequency.get)  # Самое частое слово\n",
    "    most_frequent_word_count = word_frequency[most_frequent_word]  # Количество повторений самого частого слова\n",
    "\n",
    "    return total_words, unqiue_words, most_frequent_word, most_frequent_word_count\n",
    "\n",
    "\n",
    "# text = input(\"Введите текст: \")  # Можно раскомментировать и задать другой текст. Следующую строку тогда закомментировать\n",
    "text = 'На лугу паслись три коровы белая корова кормила маленького теленка теленка все время бегал за коровой коровой за коровой три коровы красивые корова паслись красивой зеленой траве траве луга траве луга красивого красивого луга пришла дождя дождя начался дождь дождь ливень дождь лил как из ведра ведра все мокрые коровы бежали крыши дома дома крыши как бежали три коровы бежали как бежали как мычали коровы мычали коровы мычали мычали коровы'\n",
    "analyze_text(text)\n",
    "\n",
    "\n",
    "# Можно ещё поработать с кодом, чтобы удаление знаков препинания происходило до подсчёта уникальных слов.\n",
    "# Если в тексте будут знаки, подсчёт частоты каждого слова работает корректно, а вот подсчёт количества уникальных слов уже не корректен."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy\n",
    "\n",
    "### Сравнение производительности NumPy и списков Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Сравнение производительности сложения элементов в списках и массивах NumPy\n",
    "size = 1000000\n",
    "\n",
    "# Создание списков и массивов\n",
    "list1 = list(range(size))\n",
    "list2 = list(range(size))\n",
    "array1 = np.array(list1)\n",
    "array2 = np.array(list2)\n",
    "\n",
    "# Сложение элементов в списках\n",
    "start_time = time.time()\n",
    "result_list = [x + y for x, y in zip(list1, list2)]\n",
    "print('Сложение списков:', time.time() - start_time, 'секунд')\n",
    "\n",
    "# Сложение элементов в массивах NumPy\n",
    "start_time = time.time()\n",
    "result_array = array1 + array2\n",
    "print('Сложение массивов NumPy:', time.time() - start_time, 'секунд')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "`Pandas` - это библиотека, которая позволяет удобно работать с таблицами. Как и в `numpy`, некоторые компоненты библиотеки `pandas` написаны на языке `C`, что ощутимо ускоряет работу с таблицами, содержащими большие объёмы данных.\n",
    "\n",
    "## Series\n",
    "\n",
    "`Series` - это одна из структур данных библиотеки `pandas`. Она представляет собой что-то вроде словаря, однако, является упорядоченной.\n",
    "\n",
    "Создадим какой-нибудь список, а затем получим на его основе объект `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Для установки в windows, ввести в терминале    pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 3, 5, 7, 2]\n",
    "\n",
    "b = pd.Series(a)\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате такой операции получается объект `Series`, содержащий элементы из списка `a`. Здесь справа располагаются элементы из `a`, а слева - их индексы. Поскольку индексы для этих элементов мы явно не указали, используются стандартные.\n",
    "\n",
    "Индексы можно также указать явно, для этого нужно подать в качестве аргумента `index` список из индексов. Данный список должен быть той же длины, что и список `a`.\n",
    "\n",
    "В качестве индексов можно использовать что угодно: числа, строки и пр. Например, проиндексируем наш список `a` объектами типа `datetime.date`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [date(2019, 4, i) for i in a]\n",
    "\n",
    "c = pd.Series(a, index=index)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индексы можно задать сразу, а можно и изменить позже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.index = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим индексы объекта `Series` поподробнее. Их можно получить с помощью атрибута `c.index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что в качестве индексов здесь используются объекты типа `object`. Этот тип объектов используется также в `numpy`. Он используется для объектов, для которых заранее не известно, сколько памяти они требуют (в отличие от, например, `numpy.int64`, для которого заранее известно, сколько памяти под него нужно).\n",
    "\n",
    "Тип `object` в `numpy` и `pandas` приписывается, например, строкам, а также объектам из других библиотек. В массивы данных, состоящие из объектов типа `object` (например, в наш массив `c.index`), помещаются не сами объекты, а лишь указатели на них, а сами объекты хранятся в специально выделенном месте. Мы всё ещё можем использовать для этих объектов методы, присущие им (например, для каждого индекса из массива `c.index` мы можем посмотреть его год, месяц или день):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c.index[0].month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, это возможно делать лишь с отдельными элементами из индекса.\n",
    "\n",
    "В `pandas`, как и в `numpy`, возможно выполнять различные операции с массивами целиком, но лишь когда эти массивы содержат объекты типов, поддерживаемых `numpy` и `pandas` (вроде `numpy.int32` или `numpy.float64`).\n",
    "\n",
    "Для работы с датой и временем в `numpy` также есть специальный тип: `numpy.datetime64`. Приведём элементы нашего индекса к этому типу и посмотрим, что это нам позволит делать. Это можно сделать с помощью функции `pd.to_datetime`, которая получает на вход массив и возвращает новый массив, элементы которого приведены к типу `numpy.datetime64`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.index = pd.to_datetime(c.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем, например, посмотреть атрибут `day` у всех элементов индекса одновременно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c.index.day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индексы в `Series` не обязаны быть уникальными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.Series(a, index=[0, 1, 0, 1, 0])\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тип данных в `Series` можно также задать явно. Можно это сделать либо сразу же:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = pd.Series(a, dtype=np.float32)\n",
    "\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "либо позже с помощью метода `.astype`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = pd.Series(a)\n",
    "\n",
    "e = e.astype(np.float32)\n",
    "\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создать массив `Series` можно не только из списка, но и из словаря. В таком случае, ключи этого словаря становятся индексами, а соответствующие значения словаря - значениями массива:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = {\n",
    "    \"1st\": \"a\",\n",
    "    \"2nd\": \"b\",\n",
    "    \"3rd\": \"c\",\n",
    "}\n",
    "\n",
    "f = pd.Series(dict_)\n",
    "\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения массива `Series` можно получить с помощью атрибута `.values`. Значения массива представлены как `numpy.ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор данных из массива Series\n",
    "\n",
    "Для получения значений массива `Series` по индексу используется тот же синтаксис, что и с массивами в `numpy`:\n",
    "\n",
    "* Чтобы получить значение или значения по одному индексу, достаточно поставить этот индекс в квадратные скобки после массива: `f[\"1st\"]`.\n",
    "* Если необходимо получить значения по нескольким индексам, в квадратные скобки массива подаётся список индексов: `f[[\"1st\", \"3rd\"]]`.\n",
    "\n",
    "У массивов `Series` также имеются методы `.head` и `.tail`, позволяющие посмотреть, соответственно, первые несколько или последние несколько значений массива. В каждом из этих методов можно указать, сколько именно значений нужно вернуть. По умолчанию возвращается 5 значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для массивов `Series`, также как и для `numpy`-массивов, доступна булева индексация. С помощью неё можно получать значения массива, которые удовлетворяют некоторому условию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e[e > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ранее, условия можно комбинировать, используя логические операторы \"и\" (обозначается символом $\\&$), \"или\" (символ $\\mid$) и оператор отрицания \"не\" (символ $\\sim$). При этом каждое условие необходимо поставить в круглые скобки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e[(e > 2) | (e == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменять массив `Series` можно теми же способами, что и при работе с обычными словарями. Например, команда `e[2] = 4` заменит значение массива `e` с индексом 2 на 4.\n",
    "\n",
    "Однако, в массивах `Series` мы можем менять несколько значений одновременно. Например, с помощью тех же самых условий:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e[e > 2] = -1\n",
    "\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "либо передав в массив какие-то конкретные индексы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e[[1, 3]] = 5\n",
    "\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление и удаление данных в Series\n",
    "\n",
    "С помощью метода `concat` мы можем добавлять к одному массиву `Series` другой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = pd.concat([e, f])\n",
    "\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода `.drop` мы можем удалять из массива элементы с определёнными индексами. Эти индексы мы и подаём в метод в виде списка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = g.drop([0, 4, \"2nd\"])\n",
    "\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что эти методы, в отличие от аналогичных методов из стандартных библиотек питона, не изменяют исходный массив, но возвращают новый.\n",
    "\n",
    "### Запись и чтение массивов Series из файла\n",
    "\n",
    "\n",
    "Для записи массивов `Series` в файлы используется формат файлов под названием `pickle`. Этот формат позволяет полностью сохранять питоновские объекты, а затем загружать их в неизменном виде.\n",
    "\n",
    "Для записи массива `Series` в файл используется метод `.to_pickle`, а для чтения - функция `np.read_pickle`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.to_pickle(\"h.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = pd.read_pickle(\"h.pkl\")\n",
    "\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "`DataFrame` - двумерная структура данных из библиотеки `pandas`, позволяющая удобно работать с таблицами.\n",
    "\n",
    "Самый простой способ задать `DataFrame` - с помощью словаря, в котором каждый ключ отвечает за столбец, а соответствующее значение - это список из элементов данного столбца. Эти списки должны иметь одинаковую длину."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\n",
    "    \"col1\": [1, 2, 4, 5, 6, 7, 8],\n",
    "    \"col2\": [\"a\", \"c\", \"e\", \"g\", \"z\", \"x\", \"y\"]\n",
    "}\n",
    "\n",
    "b = pd.DataFrame(a)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью атрибута `.shape` можно посмотреть форму массива `DataFrame`. Атрибут `.columns` содержит массив из столбцов, а `.index`, как и ранее, содержит массив индексов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Форма b: {}\".format(b.shape))\n",
    "\n",
    "print(\"Столбцы b: {}\".format(b.columns))\n",
    "\n",
    "print(\"Индексы b: {}\".format(b.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общую информацию о массиве можно запросить с помощью метода `.info`. Нам вернётся информация об индексах и столбцах данного массива, о том, какие типы данных хранятся в каждом из столбцов, а также информация о том, сколько памяти выделено под данный массив."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода `.describe` можно получить некоторые статистические характеристики по столбцам с числовыми значениями: среднее значение, среднее квадратическое отклонение, максимум, минимум, квантили и пр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор данных из массива DataFrame\n",
    "\n",
    "Для получения данных из массива `DataFrame` используется тот же синтаксис, что и для `Series`. Например, с помощью методов `.head` и `.tail` можно получить несколько первых или несколько последних строк таблицы.\n",
    "\n",
    "Отдельный столбец можно получить, передав его название в квадратные скобки массива:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[\"col1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый отдельный столбец массива `DataFrame` возвращается как массив типа `Series`.\n",
    "\n",
    "Если мы хотим указать несколько столбцов, в квадратные скобки нужно подать список из столбцов. Тогда нам вернётся подтаблица исходной таблицы опять в формате `DataFrame`.\n",
    "\n",
    "Получить данные из строк таблицы `DataFrame` можно получить с помощью атрибута `.loc`. Этот атрибут представляет собой что-то вроде двумерного массива. Конкретное значение (или несколько значений) этого массива можно получить, указав нужный индекс строки и название колонки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.loc[2, \"col1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ранее, вместо каждого из ключей можно подать список ключей, чтобы вернуть несколько значений. Кроме того, второй аргумент можно не указывать, тогда будут возвращены значения из всех столбцов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.loc[[0, 2, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При использовании атрибута `.loc` мы должны указывать именно индекс нужной строки и название нужного столбца. Бывают ситуации, когда удобнее было бы получить значение по позиции (т.е., например, элемент из третьей строки и второго столбца). Для этого можно использовать атрибут `.iloc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.iloc[2, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в `Series`, в массивах `DataFrame` есть возможность использовать булеву индексацию для указания строк. Причём, условия могут касаться любого столбца или набора столбцов. Как и ранее, условия можно комбинировать с помощью логических операторов.\n",
    "\n",
    "Например, получим значения из второго столбца у всех строк, значение первого столбца для которых больше 3 или равно 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.loc[(b[\"col1\"] > 3) | (b[\"col1\"] == 1), \"col2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `pandas` есть также несколько методов, упрощающих булеву индексацию:\n",
    "\n",
    "* `b[\"col1\"].between(1, 3)` - все строки, для которых значение в первом столбце лежит между 11 и 13 (включая оба конца)\n",
    "* `b[\"col2\"].isin([\"a\", \"z\"])` - все строки, для которых значение второго столбца содержится в списке `[\"a\", \"z\"]`\n",
    "\n",
    "Их также можно использовать вместе с логическими операторами. Например, получим все строки из таблицы `b`, для которых значение первого столбца лежит между 3 и 6, а значение второго столбца не равно `\"a\"` или `\"z\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[(b[\"col1\"].between(3, 6)) & (~b[\"col2\"].isin([\"a\", \"z\"]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более короткий и удобный функционал для таких запросов реализован методом `.query`. В него подаётся строка, содержащая булевы условия на значения столбцов. При этом, переменную массива мы уже не пишем, а к столбцам обращаемся без кавычек. В остальном, допускается тот же синтаксис с использованием булевых операторов.\n",
    "\n",
    "Пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.query('(col1 < 6) & (col2 > \"c\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы уже отмечали, выбирая один столбец из `DataFrame`, мы получаем массив `Series`. Если хочется получить столбец именно в виде `DataFrame`, можно запросить запросить его, подавая в квадратные скобки не название столбца, а список, содержащий только один этот столбец:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(b[\"col1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(b[[\"col1\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В любом случае, конвертировать `Series` в `DataFrame` можно и явно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.Series([3, 1, 2])\n",
    "\n",
    "d = pd.DataFrame(c)\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если требуется скопировать массив `Series` или `DataFrame`, это можно сделать с помощью метода `.copy`: `e = d.copy()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный выбор значений из DataFrame\n",
    "\n",
    "Случайный выбор строк из массива `DataFrame` производится с помощью метода `.sample`. Вот несколько его важных параметров:\n",
    "\n",
    "* `frac` - какую долю от общего числа строк нужно вернуть (число от 0 до 1)\n",
    "* `n` - сколько строк нужно вернуть (число от 0 до числа строк в массиве)\n",
    "* `replace` - индикатор того, производится ли выбор _с возвращением_, т.е. с возможным повторением строк в выборке, или _без возвращения_ (`True` или `False`)\n",
    "\n",
    "Нельзя использовать параметры `frac` и `n` одновременно, нужно выбрать какой-то один."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.sample(frac=0.5, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если требуется просто перемешать всю выборку, это также можно выполнить с помощью метода `.sample`, передав в него параметр `frac=1`.\n",
    "\n",
    "### Запись и чтение DataFrame из файлов\n",
    "\n",
    "Для хранения таблиц широко распространён формат файлов с расширением `.csv`.\n",
    "\n",
    "Сохранить массив в файл можно с помощью метода `.to_csv`. Вот несколько важных параметров этого метода:\n",
    "\n",
    "* `sep` - символ, который нужно использовать для разделения значения столбцов между собой. По умолчанию это `\",\"`, но можно также использовать `\";\"`, `\"\\t\"` и др.\n",
    "* `index` - булево значение, индикатор того, нужно ли в файл сохранить также столбец индексов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.to_csv(\"test.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитать массив из файла можно с помощью функции `pd.read_csv`. Здесь также можно указать разделитель столбцов в параметре `sep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_csv(\"test.csv\", sep=\";\")\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У данных команд для сохранения и чтения таблиц есть множество других важных и полезных параметров, поэтому рекомендуется также изучить их документацию: [to_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html), [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).\n",
    "\n",
    "В `pandas` также имеются аналогичные команды для сохранения и записи таблиц как `excel` и `pickle`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с данными в Pandas\n",
    "\n",
    "### Слияние данных\n",
    "\n",
    "Рассмотрим следующий пример. Допустим, что мы работаем с небольшим отделом книжного магазина, в котором продаётся классическая литература на английском языке. Наша задача - систематизировать ассортимент отдела.\n",
    "\n",
    "У нас есть таблица `authors`, содержащая данные об авторах: их идентификаторы (`author_id`) и имена (`author_name`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = pd.DataFrame({\n",
    "    'author_id': [1, 2, 3],\n",
    "    'author_name': ['Pushkin', 'Tolstoy', 'Dostoevsky'],\n",
    "})\n",
    "\n",
    "authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, у нас есть таблица `books`, содержащая информацию о книгах этих авторов. В этой таблице также есть колонка `author_id`, а также колонка `book_title`, содержащая название книги:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.DataFrame({\n",
    "    'author_id': [2, 3, 3, 4],\n",
    "    'book_title': ['War and Peace', 'The Idiot', 'Crime and Punishment',\n",
    "                   'Fathers and Sons'],\n",
    "})\n",
    "\n",
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что делать, если мы, например, захотим сопоставить названия книг именам их авторов? Для этого используется функция `pd.merge`: в эту функцию помещаются те таблицы, которые мы хотим соединить, а также несколько других важных аргументов:\n",
    "\n",
    "* `on` - параметр, отвечающий за то, какой столбец мы будем использовать для слияния,\n",
    "* `how` - каким образом производить слияние.\n",
    "\n",
    "Опишем подробнее, какие значения может принимать параметр `how`:\n",
    "\n",
    "* `\"inner\"` - внутреннее слияние. В этом случае в слиянии участвуют только те строки, которые присутствуют в обоих таблицах,\n",
    "* `\"left\"` - в слиянии участвуют все строки из левой таблицы,\n",
    "* `\"right\"` - то же самое, но для правой таблицы,\n",
    "* `\"outer\"` - внешнее слияние, соединяются все строки как из левой, так и из правой таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(authors, books, on='author_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы выбираем `\"left\"`, `\"right\"` или `\"outer\"`, может случиться так, что строку из одной таблицы будет невозможно соединить со второй. Например, мы видим, что в нашей таблице `books` нет произведений Пушкина (его `id` равен 1). В свою очередь, в таблице `books` есть книга, для которой `author_id` равен 4, хотя, в таблице `authors` нет записи с таким `author_id`. Рассмотрим внешнее слияние этих таблиц:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(authors, books, on='author_id', how='outer')\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, в получившейся таблице присутствуют пропущенные значения (`NaN`).\n",
    "\n",
    "### Работа с пропущенными данными\n",
    "\n",
    "Пропущенные значения в `Series` или `DataFrame` можно получить с помощью метода `.isnull`. Наоборот, все имеющиеся непустые значения можно получить с помощью метода `.notnull`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[merged_df[\"author_name\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[merged_df[\"author_name\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнить пропущенные значения каким-то своим значением можно с помощью метода `.fillna()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"author_name\"] = merged_df[\"author_name\"].fillna(\"unknown\")\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление столбцов в `DataFrame`.\n",
    "\n",
    "Допустим, каждая из наших книг имеется в единственном экземпляре. Мы хотели бы создать в таблице `merged_df` столбец `quantity`, который бы содержал количество экземпляров каждой книги.\n",
    "\n",
    "Создание нового столбца в таблице `DataFrame` происходит аналогично созданию нового значения в словаре `dict`. Достаточно просто объявить значение `merged_df[\"quantity\"]`. Если подать в это значение какое-нибудь число или строку, то все значения в данном столбце приравняются к этому числу или строке. Также можно подать сюда список, тогда значения из этого списка поступят в соответствующие строки этого столбца. В этом случае длина списка обязана совпадать с числом строк таблицы.\n",
    "\n",
    "Итак, выберем все строки с непустым значением поля `book_title`, и для них запишем в столбец `quantity` число 1. Это можно сделать с помощью атрибута `.loc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[merged_df[\"book_title\"].notnull(), \"quantity\"] = 1\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь заполним все пропуски в этом столбце числом 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"quantity\"].fillna(0, inplace=True)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, приведём значения в этом столбце к типу `int`. (Это сделать невозможно, если в столбце содержатся пропуски.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"quantity\"] = merged_df[\"quantity\"].astype(int)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `DataFrame` можно использовать индексы по умолчанию, а можно и назначить свои. Например, в качестве индексов можно использовать какой-нибудь из столбцов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.set_index(\"author_id\", inplace=True)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если что, индексы всегда можно сбросить. Тогда текущие индексы становятся столбцом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.reset_index(inplace=True)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление данных\n",
    "\n",
    "Для удаления данных из `DataFrame` используется метод `.drop`. В этот метод подаётся метка элемента, который необходимо удалить (индекс строки или название столбца), а также ось `axis`. При `axis=0` удаляется строка, при значении `axis=1` - столбец:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"price\"] = 500\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(\"price\", axis=1, inplace=True)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь удалим строку с индексом 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(1, axis=0, inplace=True)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сортировка данных\n",
    "\n",
    "Вернём только что удалённую строку. Напомним, что для этого используется метод `.concat`. Кстати, добавлять строки к `DataFrame` можно прямо в виде словарей `dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([merged_df,\n",
    "    pd.DataFrame({\n",
    "        \"author_id\": [2],\n",
    "        \"author_name\": [\"Tolstoy\"],\n",
    "        \"book_title\": [\"War and Peace\"],\n",
    "        \"quantity\": [1],\n",
    "    })],ignore_index=True\n",
    ")\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметр `ignore_index=True` подаётся сюда, чтобы индексы соединяемых таблиц не учитывались. В результирующей таблице будут использованы стандартные последовательные индексы, начинающиеся с 0.\n",
    "\n",
    "Отсортируем эту таблицу по столбцу `author_id`. Это делается с помощью метода `.sort_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.sort_values(by=\"author_id\", inplace=True)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы сбросить индексы, воспользуемся уже известным методом `.reset_index`. В нашем случае, стоит подать в него аргумент `drop=True`, который означает, что текущий столбец из индексов не нужно сохранять в таблице, а можно удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Соединение таблиц\n",
    "\n",
    "Для соединения таблиц можно пользоваться функцией `pd.concat`. С этой функцией мы уже знакомились, когда изучали библиотеку `numpy`. Здесь эта функция работает аналогичным образом: соединяет таблицы либо вертикально (если указан параметр `axis=0`), либо горизонтально (если `axis=1`).\n",
    "\n",
    "Соединение происходит с сохранением индексов, если не указан параметр `ignore_index=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    'author_id': [3, 5],\n",
    "    'author_name': ['Dostoevsky', 'Chekhov'],\n",
    "    'book_title': ['The Gambler', 'Three Sisters'],\n",
    "    'quantity': [2, 3],\n",
    "})\n",
    "\n",
    "df2 = pd.concat([merged_df, df1], axis=0, ignore_index=True)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(\n",
    "    {'price': [700, 450, 500, 400, 350]},\n",
    "    index=[1, 2, 3, 5, 6],\n",
    ")\n",
    "\n",
    "df4 = pd.concat([df2, df3], axis=1)\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Операции над таблицами\n",
    "\n",
    "Как и ранее с массивами `numpy` и `Series`, с таблицами `DataFrame` можно производить различные математические операции. Например, значения различных столбцов можно поэлементно перемножать, складывать и пр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[\"total\"] = df4[\"quantity\"] * df4[\"price\"]\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью следующих методов можно посчитать основные статистики по желаемым столбцам:\n",
    "\n",
    "* `df4[\"price\"].max()` - максимум\n",
    "* `df4[\"price\"].min()` - минимум\n",
    "* `df4[\"price\"].mean()` - среднее\n",
    "* `df4[\"price\"].median()` - медиана\n",
    "* `df4[\"price\"].std()` - среднее квадратическое значение\n",
    "* `df4[\"price\"].var()` - дисперсия\n",
    "\n",
    "С помощью метода `.nlargest` можно вывести несколько наибольших значений. Указывается то, сколько значений нужно вернуть, а также то, по какому именно значению нужно сортировать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.nlargest(3, \"price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеется также аналогичный метод `.nsmallest`.\n",
    "\n",
    "С помощью метода `.unique` можно получить уникальные значения заданного столбца:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[\"author_name\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нужно получить не уникальные значения, а лишь их количество, можно воспользоваться методом `.nunique`.\n",
    "\n",
    "С помощью метода `.value_counts` можно получить информацию о том, сколько раз каждое уникальное значение появляется в данном столбце:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[\"author_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К значениям таблицы можно применять и функции, которые не имеются в библиотеках `pandas` и `numpy`. Делается это с помощью метода `.apply`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[\"author_name\"].apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Группировка данных\n",
    "\n",
    "Данные в таблице `DataFrame` можно группировать по повторяющимся значениям выбранного столбца. Группировка позволяет вычислять какие-то _агренированные_ значения, т.е. значения, полученные каким-то образом из групп других значений. Например, если мы захотим сгруппировать нашу таблицу по значениям `author_name`, то каждая группа будет содержать все строки с одинаковым значением `author_name`. По таким группам можно затем посчитать какую-нибудь агрегирующую функцию, например, сумму, среднее, минимум и др.\n",
    "\n",
    "Вот несколько способов это сделать. В первом случае мы просто выбираем конкретный столбец из группировки и применяем к нему какую-то агрегирующую функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby = df4.groupby(\"author_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby[\"price\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй способ - с помощью метода `.agg`. Данный метод является более гибким. Например, он позволяет вычислять одновременно несколько различных агрегирующих функций от разных столбцов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby.agg({\"price\": \"max\", \"total\": \"count\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # Для установки в windows, ввести в терминале    pip install matplotlib\n",
    "import numpy as np  # Для работы с массивами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure - это контейнер самого верхнего уровня, та область на которой все нарисовано. Таких областей может быть несколько, каждая из которых может содержать несколько контейнеров Axes.\n",
    "\n",
    "\n",
    "Axes - это та область на которой чаще всего и отражаются графики (данные в виде графиков), а так же все вспомогательные атрибуты (линии сетки, метки, указатели и т.д.). Часто, установка этой области сопровождается с вызовом subplot, который и помещает Axes на регулярную сетку. Поэтому, так же часто Axes и Subplot можно считать синонимами. Но с тем что это за сетка и как это размещение работает, давайте разберемся чуть ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим объекты Figure и Axes(subplot)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "fig.set(facecolor=\"green\")\n",
    "ax.set(facecolor = \"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для наглядности создадим создадим Figure с 3-мя Axes\n",
    "\n",
    "fig, axes = plt.subplots(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим линейный график\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "x = np.linspace(0, 30, 10)\n",
    "y = x\n",
    "\n",
    "ax.plot(x, y, color=\"red\", linestyle=\"--\", label=\"legend_1\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set(title=\"График 1\", xlabel=\"Ось x\", ylabel=\"Ось Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим линейный график без явного создания объектов Figure и Axes\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим несколько графиков\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "x = np.linspace(0, 30, 10)\n",
    "y1 = x\n",
    "y2 = [i**2 for i in x]\n",
    "\n",
    "ax.plot(x, y1, color=\"red\", linestyle=\"--\", label=\"legend_1\")\n",
    "ax.plot(x, y2, color=\"black\", linestyle=\"-\", label=\"legend_2\")\n",
    "\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set(title=\"График 1\", xlabel=\"Ось x\", ylabel=\"Ось Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение несколько графиков отдельно друг от друга (на разных полях)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2)\n",
    "\n",
    "x = np.linspace(0, 30, 10)\n",
    "y1 = x\n",
    "y2 = [i**2 for i in x]\n",
    "y3 = [-i**2 for i in x]\n",
    "y4 = [np.sin(i) for i in x]\n",
    "\n",
    "# axes[0, 0].plot(x, y1)\n",
    "# axes[0, 1].plot(x, y2)\n",
    "# axes[1, 0].plot(x, y3)\n",
    "# axes[1, 1].plot(x, y4)\n",
    "\n",
    "for ax, y in zip(axes.flatten(), [y1, y2, y3, y4]):\n",
    "    ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Стековый график\n",
    "\n",
    "\"\"\"\n",
    "Для построения стекового графика используется функция stackplot().\n",
    "Суть его в том, что графики отображаются друг над другом, и каждый следующий является суммой предыдущего и заданного:\n",
    "\"\"\"\n",
    "\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y1 = [1, 1, 2, 3, 5]\n",
    "y2 = [0, 4, 2, 6, 8]\n",
    "y3 = [1, 3, 5, 7, 9]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.stackplot(x, y1, y2, y3, labels=['y1', 'y2', 'y3'])\n",
    "ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Точечный график\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.arange(0, 10.5, 0.5)\n",
    "y = np.cos(x)\n",
    "ax.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Столбчатые диаграммы\n",
    "\n",
    "\"\"\"\n",
    "Для визуализации категориальных данных хорошо подходят столбчатые диаграммы. Для их построения используются функции:\n",
    "bar() — вертикальная столбчатая диаграмма;\n",
    "barh() — горизонтальная столбчатая диаграмма;\n",
    "\"\"\"\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "labels = [f'P{i}' for i in range(7)]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "counts = np.random.randint(3, 10, len(labels))\n",
    "\n",
    "ax.bar(x, counts)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Групповые столбчатые диаграмма\n",
    "# Используя определенным образом подготовленные данные, можно строить групповые диаграммы:\n",
    "\n",
    "labels = [f'P{i}' for i in range(5)]\n",
    "g1 = [10, 21, 34, 12, 27]\n",
    "g2 = [17, 15, 25, 21, 26]\n",
    "width = 0.3\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(x , g1, width, label='g1')\n",
    "ax.bar(x + width/2, g2, width, label='g2')\n",
    "\n",
    "ax.set(title=\"Пример групповой диаграммы\", xticks=x, xticklabels=labels)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Круговые диаграммы\n",
    "\n",
    "\"\"\"\n",
    "Это наглядный способ показать доли компонентов в наборе.\n",
    "Они идеально подходят для отчётов, презентаций и т.п.\n",
    "Для построения круговых диаграмм в Matplotlib используется функция pie().\n",
    "\"\"\"\n",
    "\n",
    "vals = [24, 17, 53, 21, 35]\n",
    "labels = ['Ford', 'Toyota', 'BMW', 'AUDI', 'Jaguar']\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.pie(vals, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Быстрый старт в seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns  # Для установки в windows, ввести в терминале    pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.get_dataset_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим датасет по автомобилям\n",
    "\n",
    "mpg = sns.load_dataset(\"mpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Построим зависимость ускорения (acceleration) от количества лошадиных сил (horsepower),\n",
    "при этом размер точки будет определяться количеством цилиндров\n",
    "\"\"\"\n",
    "\n",
    "sns.relplot(x=\"horsepower\", y=\"acceleration\", size=\"cylinders\", kind=\"scatter\", data=mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Для демонстрации работы функции построения линейного графика загрузим набор данных flights,\n",
    "содержащий информацию о количестве пассажиров, которые воспользовались авиатранспортом:\n",
    "\"\"\"\n",
    "\n",
    "flights = sns.load_dataset(\"flights\")\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"year\", y=\"passengers\", kind=\"line\", data=flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://seaborn.pydata.org/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset(\"iris\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Загруженный набор данных является эталонным для изучения алгоритмов классификации,\n",
    "он представляет собой информацию о 150 экземплярах ириса по 50 на каждый отдельный вид:\n",
    "Ирис щетинистый (setosa), Ирис Виргинский (virginica) и Ирис разноцветный (versicolor).\n",
    "Для каждого экземпляра определены следующие параметры:\n",
    "• Длина наружной доли околоцветника (sepal_length);\n",
    "• Ширина наружной доли околоцветника (sepal_width);\n",
    "• Длина внутренней доли околоцветника (petal_length);\n",
    "• Ширина внутренней доли околоцветника (petal_width).\n",
    "\"\"\"\n",
    "\n",
    "sns.boxplot(x=\"species\", y=\"sepal_length\", data=iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Результаты бегунов (в секундах)\n",
    "results = np.array([12.4, 11.8, 13.2, 12.1, 11.5, 12.7, 11.9, 12.3, 12.0, 11.7])\n",
    "\n",
    "# Среднее время\n",
    "mean_time = np.mean(results)\n",
    "print(f\"Среднее время: {mean_time} секунд\")\n",
    "\n",
    "# Медианное время\n",
    "median_time = np.median(results)\n",
    "print(f\"Медианное время: {median_time} секунд\")\n",
    "\n",
    "# Стандартное отклонение\n",
    "std_deviation = np.std(results)\n",
    "print(f\"Стандартное отклонение: {std_deviation} секунд\")\n",
    "\n",
    "# Лучший и худший результат\n",
    "best_time = np.min(results)\n",
    "worst_time = np.max(results)\n",
    "print(f\"Лучшее время: {best_time} секунд\")\n",
    "print(f\"Худшее время: {worst_time} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Данные о недвижимости\n",
    "data = {\n",
    "    'Price': [300000, 450000, 350000, 500000, 400000],\n",
    "    'Rooms': [3, 4, 3, 5, 4],\n",
    "    'Area': [120, 200, 150, 250, 180],\n",
    "    'Location': ['North', 'West', 'North', 'East', 'West']\n",
    "}\n",
    "\n",
    "# Создание DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Средняя цена домов в каждом районе\n",
    "mean_price_by_location = df.groupby('Location')['Price'].mean()\n",
    "print(\"Средняя цена домов в каждом районе:\\n\", mean_price_by_location)\n",
    "\n",
    "# Дом с самой высокой и самой низкой ценой\n",
    "max_price_home = df.loc[df['Price'].idxmax()]\n",
    "min_price_home = df.loc[df['Price'].idxmin()]\n",
    "print(\"Дом с самой высокой ценой:\\n\", max_price_home)\n",
    "print(\"Дом с самой низкой ценой:\\n\", min_price_home)\n",
    "\n",
    "# Средняя площадь домов\n",
    "mean_area = df['Area'].mean()\n",
    "print(f\"Средняя площадь домов: {mean_area} кв.м.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 3\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Данные о доходах и расходах\n",
    "data = {\n",
    "    'Year': [2020, 2020, 2020, 2021, 2021, 2021],\n",
    "    'Month': ['January', 'February', 'March', 'January', 'February', 'March'],\n",
    "    'Income': [5000, 5200, 5300, 5500, 5800, 6000],\n",
    "    'Expense': [4000, 4100, 4200, 4300, 4400, 4500]\n",
    "}\n",
    "\n",
    "# Создание DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Создание линейных графиков для отображения доходов и расходов по месяцам\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Линейный график доходов\n",
    "for year in df['Year'].unique():\n",
    "    yearly_data = df[df['Year'] == year]\n",
    "    plt.plot(yearly_data['Month'], yearly_data['Income'], marker='o', label=f'Доход {year}')\n",
    "\n",
    "# Линейный график расходов\n",
    "for year in df['Year'].unique():\n",
    "    yearly_data = df[df['Year'] == year]\n",
    "    plt.plot(yearly_data['Month'], yearly_data['Expense'], marker='x', label=f'Расход {year}', linestyle='--')\n",
    "\n",
    "plt.xlabel('Месяц')\n",
    "plt.ylabel('Сумма')\n",
    "plt.title('Доходы и расходы по месяцам')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Создание столбчатого графика для сравнения общего дохода и расхода за год\n",
    "total_income = df.groupby('Year')['Income'].sum()\n",
    "total_expense = df.groupby('Year')['Expense'].sum()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "width = 0.4  # Ширина столбцов\n",
    "years = df['Year'].unique()\n",
    "\n",
    "plt.bar(years - width/2, total_income, width=width, label='Доход')\n",
    "plt.bar(years + width/2, total_expense, width=width, label='Расход')\n",
    "\n",
    "plt.xlabel('Год')\n",
    "plt.ylabel('Сумма')\n",
    "plt.title('Общий доход и расход за год')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(years)  # Установка меток для оси X\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
